{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/anaconda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /opt/anaconda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu/'\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "import wandb\n",
    "import os\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModelForSeq2SeqLM\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PrefixTuningConfig, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from peft import PeftModel, PeftConfig\n",
    "from glob import glob \n",
    "from collections import defaultdict, Counter\n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # replace the 0 with other gpu ids\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "torch.cuda.set_device(0)\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Talkdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5208\n",
      "5208\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quotedpost</th>\n",
       "      <th>quotedreply</th>\n",
       "      <th>label</th>\n",
       "      <th>post</th>\n",
       "      <th>reply</th>\n",
       "      <th>post_user</th>\n",
       "      <th>reply_user</th>\n",
       "      <th>start_offset</th>\n",
       "      <th>end_offset</th>\n",
       "      <th>reddit_post_id</th>\n",
       "      <th>reddit_reply_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Please educate yoyrself before you bring your ...</td>\n",
       "      <td>Not condescending at all, jeez.</td>\n",
       "      <td>True</td>\n",
       "      <td>Well a guy is saying Barra, who has those grea...</td>\n",
       "      <td>&gt; Please educate yoyrself before you bring you...</td>\n",
       "      <td>StalinHimself</td>\n",
       "      <td>Kel_Casus</td>\n",
       "      <td>135</td>\n",
       "      <td>208</td>\n",
       "      <td>dbl4vl9</td>\n",
       "      <td>dblfraj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There might be some small piece that's incorrect</td>\n",
       "      <td>You said that. Not me. Not James-Cizuz. You sa...</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt; I think you're the one who has a reading com...</td>\n",
       "      <td>&gt; theories are constantly growing and evolving...</td>\n",
       "      <td>kishi</td>\n",
       "      <td>jids</td>\n",
       "      <td>365</td>\n",
       "      <td>413</td>\n",
       "      <td>c2dtpq9</td>\n",
       "      <td>c2dtywp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If I try and force down a breakfast I start ga...</td>\n",
       "      <td>Yes!\\n\\nPeople were so condescending about it ...</td>\n",
       "      <td>False</td>\n",
       "      <td>For me it's like temporarily having the flu. T...</td>\n",
       "      <td>&gt; If I try and force down a breakfast I start ...</td>\n",
       "      <td>amphetaminesfailure</td>\n",
       "      <td>CowGiraffe</td>\n",
       "      <td>331</td>\n",
       "      <td>383</td>\n",
       "      <td>cuv97mf</td>\n",
       "      <td>cuvnb27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nonviolence leads to reform and progress. It's...</td>\n",
       "      <td>I don't believe you, you provide no examples, ...</td>\n",
       "      <td>True</td>\n",
       "      <td>Uh, no. Nonviolence leads to reform and progre...</td>\n",
       "      <td>&gt;Nonviolence leads to reform and progress. It'...</td>\n",
       "      <td>UmamiSalami</td>\n",
       "      <td>ArizonaIcedOutBoys</td>\n",
       "      <td>8</td>\n",
       "      <td>102</td>\n",
       "      <td>cmb6odf</td>\n",
       "      <td>cmbb0la</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have you actually read the bible ??</td>\n",
       "      <td>Is that where you learned how to be condescend...</td>\n",
       "      <td>True</td>\n",
       "      <td>&gt;Do you not understand how insensitive and rud...</td>\n",
       "      <td>&gt; Have you actually read the bible ??\\n\\nIs th...</td>\n",
       "      <td>lju1977</td>\n",
       "      <td>katapliktikos</td>\n",
       "      <td>58</td>\n",
       "      <td>93</td>\n",
       "      <td>cqq300a</td>\n",
       "      <td>cqq3289</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          quotedpost   \n",
       "0  Please educate yoyrself before you bring your ...  \\\n",
       "1   There might be some small piece that's incorrect   \n",
       "2  If I try and force down a breakfast I start ga...   \n",
       "3  Nonviolence leads to reform and progress. It's...   \n",
       "4                Have you actually read the bible ??   \n",
       "\n",
       "                                         quotedreply  label   \n",
       "0                    Not condescending at all, jeez.   True  \\\n",
       "1  You said that. Not me. Not James-Cizuz. You sa...   True   \n",
       "2  Yes!\\n\\nPeople were so condescending about it ...  False   \n",
       "3  I don't believe you, you provide no examples, ...   True   \n",
       "4  Is that where you learned how to be condescend...   True   \n",
       "\n",
       "                                                post   \n",
       "0  Well a guy is saying Barra, who has those grea...  \\\n",
       "1  > I think you're the one who has a reading com...   \n",
       "2  For me it's like temporarily having the flu. T...   \n",
       "3  Uh, no. Nonviolence leads to reform and progre...   \n",
       "4  >Do you not understand how insensitive and rud...   \n",
       "\n",
       "                                               reply            post_user   \n",
       "0  > Please educate yoyrself before you bring you...        StalinHimself  \\\n",
       "1  > theories are constantly growing and evolving...                kishi   \n",
       "2  > If I try and force down a breakfast I start ...  amphetaminesfailure   \n",
       "3  >Nonviolence leads to reform and progress. It'...          UmamiSalami   \n",
       "4  > Have you actually read the bible ??\\n\\nIs th...              lju1977   \n",
       "\n",
       "           reply_user  start_offset  end_offset reddit_post_id reddit_reply_id  \n",
       "0           Kel_Casus           135         208        dbl4vl9         dblfraj  \n",
       "1                jids           365         413        c2dtpq9         c2dtywp  \n",
       "2          CowGiraffe           331         383        cuv97mf         cuvnb27  \n",
       "3  ArizonaIcedOutBoys             8         102        cmb6odf         cmbb0la  \n",
       "4       katapliktikos            58          93        cqq300a         cqq3289  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_dir = '/shared/2/projects/contextual-appropriateness/data/talkdown/'\n",
    "\n",
    "talkdown_train_df = pd.read_json(td_dir + 'balanced_train.jsonl', lines=True)\n",
    "talkdown_test_df = pd.read_json(td_dir + 'balanced_test.jsonl', lines=True)\n",
    "\n",
    "print(len(talkdown_train_df))\n",
    "\n",
    "#talkdown_train_df.drop_duplicates(inplace=True,ignore_index=True, subset='quotedpost', keep=\"first\")\n",
    "print(len(talkdown_train_df))\n",
    "talkdown_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_to_verbalization = {\n",
    "    \"friend\": \"a person to their friend\",\n",
    "    \"parent\":\"a parent to their child\",\n",
    "    \"child\":\"a child to their parent\",\n",
    "    \"sibling\":\"a person to their sibling\",\n",
    "    \"best friend\":\"a person to their best friend\",\n",
    "    \"best_friend\":\"a person to their best friend\",\n",
    "    \"neighbor\":\"a person to their neighbor\",\n",
    "    \"coworker\":\"a person to their coworker\",\n",
    "    \"boss\":\"a boss to their employee\",\n",
    "    \"direct report (employee)\":\"a person to their boss\",\n",
    "    \"direct_report\":\"a person to their boss\",    \n",
    "    \"student\":\"a student to their teacher\",\n",
    "    \"teacher\":\"a teacher to their student\",\n",
    "    \"cousins\":\"a person to their cousin\",\n",
    "    \"granparent\":\"a person to their grandchild\",\n",
    "    \"grandparent\":\"a person to their grandchild\",\n",
    "    \"grandchild\":\"a person to their grandparent\",    \n",
    "    \"uncle/aunt\":\"an uncle/aunt to their niece or nephew\",\n",
    "    \"uncle_aunt\":\"an uncle or aunt to their niece or nephew\",    \n",
    "    \"neice_nephew\":\"a niece or nephew to their uncle or aunt\",        \n",
    "    \"employee_in_large_company\":\"an employee in large company to another\",\n",
    "    \"married\":\"a person to their spouse\",\n",
    "    \"dating\":\"a person to the person they are dating\",\n",
    "    \"engaged\":\"a person to their fiancee\",\n",
    "    \"friends_with_benefits\":\"a person to their friend with benefits\",\n",
    "    \"divorcee\":\"a person to their ex-spouse\",\n",
    "    \"ex-girlfriend/ex-boyfriend\":\"a person to their ex-girlfriend or ex-boyfriend\",\n",
    "    \"ex_dating\":\"a person to their ex-girlfriend or ex-boyfriend\",    \n",
    "    \"step-sibling\":\"a person to their step-sibling\",\n",
    "    \"step_sibling\":\"a person to their step-sibling\",    \n",
    "    \"fan\":\"a fan to their hero\",\n",
    "    \"hero\":\"a hero to their fan\",\n",
    "    \"enemy\":\"a person to their enemy\",\n",
    "    \"rival\":\"a person to their rival\",\n",
    "    \"competitor\":\"a person to their competitor\",\n",
    "    \"complete_stranger\":\"a person to a complete stranger\",\n",
    "    \"acquaintance\":\"a person to an acquaintance\",\n",
    "    \"person_with_authority\":\"a person with authority to a subordinate\",\n",
    "    \"law_enforcement\":\"a member of law enforcement to a community member\",\n",
    "    \"classmate\":\"a person to their classmate\",\n",
    "    \"sports_teammate\":\"a person to their sports teammate\",\n",
    "    \"club_member\":\"a person to a member of their club\",\n",
    "    \"adopted_child\":\"an adopted child to their parent\",\n",
    "    \"adopted child\":\"an adopted child to their parent\",\n",
    "    \"domestic_partner\":\"a person to their domestic partner\",\n",
    "    \"person_having_an_affair\":\"a person having an affair to their partner\",\n",
    "    \"mentor\":\"a mentor to their mentee\",\n",
    "    \"mentee\":\"a mentee to their mentor\",\n",
    "    \"landlord\":\"a landlord to their tenant\",\n",
    "    \"colleague\":\"a person to their colleague\",\n",
    "    \"childhood_friend\":\"a person to their childhood friend\",\n",
    "    \"old_friend\":\"a person to an old friend\",\n",
    "    \"client\":\"a client to their lawyer\",\n",
    "    \"lawyer\":\"a lawyer to their client\",\n",
    "    \"patient\":\"a patient to their doctor\",\n",
    "    \"doctor\":\"a doctor to their patient\",\n",
    "    #\"lover\":\"a person to their lover\", #relationships in PRIDE\n",
    "    #\"commercial\":\"a person to someone in a commercial relationship\",#relationships in PRIDE\n",
    "    #\"church\":\"a person to someone in their church\" #relationships in PRIDE    \n",
    "}\n",
    "len(relationship_to_verbalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '/shared/2/projects/contextual-appropriateness/data/final-annotated-data-cleaned/'\n",
    "train_df = pd.read_csv(datadir + 'train.csv')\n",
    "rels = set(train_df.relationship)\n",
    "len(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_to_tuple = {}\n",
    "for rel, verbalization in relationship_to_verbalization.items():\n",
    "    #print(verbalization)\n",
    "    i = verbalization.index('to ')\n",
    "    v1 = verbalization[:i-1]\n",
    "    v2 = verbalization[i:].replace('to their ', '').replace('to ', '')\n",
    "    rel_to_tuple[rel] = (v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rel_to_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name_or_path = \"google/flan-t5-xl\"\n",
    "tokenizer_name_or_path = \"google/flan-t5-xl\"\n",
    "best_model_dir = '/shared/2/projects/contextual-appropriateness/models/peft/google/flan-t5-xl/seed-12345//best'\n",
    "\n",
    "text_column = \"text1\"\n",
    "label_column = \"answer\"\n",
    "max_length = 196\n",
    "lr = 1e-2\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ntok(text):\n",
    "    return len(tokenizer(text)['input_ids'])\n",
    "\n",
    "def shrink(quote, reply, total_prompt_len):\n",
    "\n",
    "    qids = tokenizer(quote)['input_ids']\n",
    "    rids = tokenizer(reply)['input_ids']   \n",
    "    plen = total_prompt_len - (len(qids) + len(rids))\n",
    "    \n",
    "    surplus = len(qids) + len(rids) - (max_length - plen)\n",
    "    \n",
    "    # Try trimming the quote first\n",
    "    if len(qids) > 50:               \n",
    "        qtrim = max(50, len(qids) - surplus)\n",
    "        qids = qids[:qtrim]\n",
    "        \n",
    "    surplus = len(qids) + len(rids) - (max_length - plen)\n",
    "\n",
    "\n",
    "    qtrim = max(10, len(qids)-int(surplus/2))    \n",
    "    qids = qids[:qtrim]\n",
    "    surplus = len(qids) + len(rids) - (max_length - plen)\n",
    "    rids = rids[:len(rids)-surplus]\n",
    "            \n",
    "    quote = tokenizer.decode(qids)\n",
    "    reply = tokenizer.decode(rids)\n",
    "            \n",
    "    return quote, reply       \n",
    "\n",
    "def verbalize(rel, quote, reply):\n",
    "    parties = rel_to_tuple[rel]\n",
    "    rel_phrase = relationship_to_verbalization[rel]\n",
    "        \n",
    "    text1 = ('Rate whether it is inappropriate for message A to be said in response ' + \\\n",
    "            'to the message B in the specified social setting:\\n' + \\\n",
    "            'A: %s\\n' + \\\n",
    "            'B: %s\\n' + \\\n",
    "            'setting: %s\\n' + \\\n",
    "            'answer (yes or no):') % (reply, quote, rel_phrase)\n",
    "\n",
    "    l = ntok(text1)\n",
    "    if l > max_length:\n",
    "        quote, reply = shrink(quote, reply, l)\n",
    "        text1 = ('Rate whether it is inappropriate for message A to be said in response ' + \\\n",
    "                'to the message B in the specified social setting:\\n' + \\\n",
    "                'A: %s\\n' + \\\n",
    "                'B: %s\\n' + \\\n",
    "                'setting: %s\\n' + \\\n",
    "                'answer (yes or no):') % (reply, quote, rel_phrase)            \n",
    "        \n",
    "    text2 = 'Is inappropriate for a %s to say \"%s\" to a %s in response to %s, yes or no?' \\\n",
    "        % (parties[0], reply, parties[1], quote)\n",
    "            \n",
    "    #return pd.Series({'format1': text1, 'format2': text2})\n",
    "    return text1, text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.is_fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf561a41668a44f592c60409b7063c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (751 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "255192"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rel_talkdown_df = defaultdict(list)\n",
    "for row in tqdm(talkdown_train_df.itertuples(), total=len(talkdown_train_df)):\n",
    "    for rel in rels:\n",
    "        all_rel_talkdown_df['reddit_reply_id'].append(row.reddit_reply_id)\n",
    "        t1, t2 = verbalize(rel, row.quotedpost, row.quotedreply)\n",
    "        all_rel_talkdown_df['text1'].append(t1)\n",
    "        all_rel_talkdown_df['text2'].append(t2)       \n",
    "        all_rel_talkdown_df['relationship'].append(rel)\n",
    "        all_rel_talkdown_df['label'].append(row.label)\n",
    "        \n",
    "all_rel_talkdown_df = pd.DataFrame(all_rel_talkdown_df)\n",
    "all_rel_talkdown_df['answer'] = 'yes'\n",
    "len(all_rel_talkdown_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f64cd34e437499abf66eaeedb72e123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/652 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "31948"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rel_talkdown_test_df = defaultdict(list)\n",
    "for row in tqdm(talkdown_test_df.itertuples(), total=len(talkdown_test_df)):\n",
    "    for rel in rels:\n",
    "        all_rel_talkdown_test_df['reddit_reply_id'].append(row.reddit_reply_id)\n",
    "        t1, t2 = verbalize(rel, row.quotedpost, row.quotedreply)\n",
    "        all_rel_talkdown_test_df['text1'].append(t1)\n",
    "        all_rel_talkdown_test_df['text2'].append(t1)       \n",
    "        all_rel_talkdown_test_df['relationship'].append(rel)\n",
    "        all_rel_talkdown_test_df['label'].append(row.label)\n",
    "        \n",
    "all_rel_talkdown_test_df = pd.DataFrame(all_rel_talkdown_test_df)\n",
    "all_rel_talkdown_test_df['answer'] = 'yes'\n",
    "len(all_rel_talkdown_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the dataframes because they're expensive to compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_outdir = '/shared/2/projects/contextual-appropriateness/results/peft/'\n",
    "all_rel_talkdown_df.to_csv(peft_outdir + 'talkdown.balanced.train.csv', index=False)\n",
    "all_rel_talkdown_test_df.to_csv(peft_outdir + 'talkdown.balanced.test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_outdir = '/shared/2/projects/contextual-appropriateness/results/peft/'\n",
    "all_rel_talkdown_df = pd.read_csv(peft_outdir + 'talkdown.balanced.train.csv')\n",
    "all_rel_talkdown_test_df = pd.read_csv(peft_outdir + 'talkdown.balanced.test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rel_talkdown_train_ds = Dataset.from_pandas(all_rel_talkdown_df)\n",
    "all_rel_talkdown_test_ds = Dataset.from_pandas(all_rel_talkdown_test_df)\n",
    "all_rel_talkdown_dd = DatasetDict()\n",
    "all_rel_talkdown_dd['train'] = all_rel_talkdown_train_ds\n",
    "all_rel_talkdown_dd['test'] = all_rel_talkdown_test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=32):   0%|          | 0/127596 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=32):   0%|          | 0/15974 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_all_rel_talkdown = all_rel_talkdown_dd.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=32,\n",
    "    remove_columns=all_rel_talkdown_dd[\"train\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801a58181e2f47d4bb1c3a86966f2e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(best_model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, best_model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93bf475b40d4a7bb50d2f9c0f927f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/829 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 154\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    processed_all_rel_talkdown['train'], shuffle=False, collate_fn=default_data_collator, \n",
    "    batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "\n",
    "train_preds = []\n",
    "for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    train_preds.extend(\n",
    "        tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), \n",
    "                               skip_special_tokens=True)\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdeb36c76f0048ed8c052f5648bb633b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 154\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    processed_all_rel_talkdown['test'], shuffle=False, collate_fn=default_data_collator, \n",
    "    batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "\n",
    "test_preds = []\n",
    "for step, batch in enumerate(tqdm(test_dataloader)):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    test_preds.extend(\n",
    "        tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), \n",
    "                               skip_special_tokens=True)\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-17eef78e7883>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  part1['predicted'] = train_preds\n",
      "<ipython-input-26-17eef78e7883>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_part1['predicted'] = test_preds\n"
     ]
    }
   ],
   "source": [
    "all_rel_talkdown_df['predicted'] = train_preds\n",
    "all_rel_talkdown_test_df['predicted'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_outdir = '/shared/2/projects/contextual-appropriateness/results/peft/'\n",
    "all_rel_talkdown_df.to_csv(peft_outdir + 'talkdown.train.balanced.labeled.csv', index=False)\n",
    "all_rel_talkdown_test_df.to_csv(peft_outdir + 'talkdown.test.balanced.labeled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
