{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu/'\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "import wandb\n",
    "import os\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModelForSeq2SeqLM\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from tqdm.auto import tqdm, trange\n",
    "from glob import glob \n",
    "from collections import defaultdict, Counter\n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_outdir = '/shared/2/projects/contextual-appropriateness/results/peft/'\n",
    "all_rel_wiki_df = pd.read_csv(peft_outdir + 'politeness.wiki.labeled.csv')\n",
    "all_rel_se_df = pd.read_csv(peft_outdir + 'politeness.se.labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix ids\n",
    "all_rel_wiki_df = all_rel_wiki_df.rename(columns={\"pride_id\": \"inst_id\"})\n",
    "all_rel_se_df = all_rel_se_df.rename(columns={\"pride_id\": \"inst_id\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Evaluate Politeness Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inst_id</th>\n",
       "      <th>text</th>\n",
       "      <th>relationship</th>\n",
       "      <th>label</th>\n",
       "      <th>answer</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Rate whether it is inappropriate for this mess...</td>\n",
       "      <td>colleague</td>\n",
       "      <td>-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Rate whether it is inappropriate for this mess...</td>\n",
       "      <td>step_sibling</td>\n",
       "      <td>-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Rate whether it is inappropriate for this mess...</td>\n",
       "      <td>sports_teammate</td>\n",
       "      <td>-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Rate whether it is inappropriate for this mess...</td>\n",
       "      <td>person_having_an_affair</td>\n",
       "      <td>-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Rate whether it is inappropriate for this mess...</td>\n",
       "      <td>domestic_partner</td>\n",
       "      <td>-1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inst_id                                               text   \n",
       "0        0  Rate whether it is inappropriate for this mess...  \\\n",
       "1        0  Rate whether it is inappropriate for this mess...   \n",
       "2        0  Rate whether it is inappropriate for this mess...   \n",
       "3        0  Rate whether it is inappropriate for this mess...   \n",
       "4        0  Rate whether it is inappropriate for this mess...   \n",
       "\n",
       "              relationship  label answer predicted  \n",
       "0                colleague     -1    yes       yes  \n",
       "1             step_sibling     -1    yes        no  \n",
       "2          sports_teammate     -1    yes       yes  \n",
       "3  person_having_an_affair     -1    yes       yes  \n",
       "4         domestic_partner     -1    yes       yes  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the long form data to features\n",
    "all_rel_wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rels = list(set(all_rel_wiki_df.relationship))\n",
    "def to_long(sdf):\n",
    "    label = list(set(sdf.label))[0]\n",
    "    d = {}\n",
    "    for row in sdf.itertuples():\n",
    "        d[row.relationship] = 1 if row.predicted == 'yes' else 0\n",
    "\n",
    "    out = { 'label': label }\n",
    "    for r in rels:\n",
    "        out[r] = d[r]\n",
    "    return pd.Series(out)\n",
    "\n",
    "wiki_df = all_rel_wiki_df.groupby('inst_id').apply(to_long)\n",
    "se_df = all_rel_se_df.groupby('inst_id').apply(to_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix issue where neutral class was included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1651, -1: 1651})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_df = se_df[se_df.label != 0]\n",
    "Counter(se_df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>married</th>\n",
       "      <th>student</th>\n",
       "      <th>person_having_an_affair</th>\n",
       "      <th>landlord</th>\n",
       "      <th>friend</th>\n",
       "      <th>law_enforcement</th>\n",
       "      <th>mentee</th>\n",
       "      <th>uncle_aunt</th>\n",
       "      <th>competitor</th>\n",
       "      <th>...</th>\n",
       "      <th>client</th>\n",
       "      <th>enemy</th>\n",
       "      <th>teacher</th>\n",
       "      <th>colleague</th>\n",
       "      <th>grandparent</th>\n",
       "      <th>classmate</th>\n",
       "      <th>adopted_child</th>\n",
       "      <th>doctor</th>\n",
       "      <th>coworker</th>\n",
       "      <th>direct_report</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inst_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label  married  student  person_having_an_affair  landlord  friend   \n",
       "inst_id                                                                       \n",
       "0           -1        0        1                        1         1       0  \\\n",
       "1            1        0        1                        0         1       0   \n",
       "2            1        0        1                        0         1       0   \n",
       "3           -1        0        1                        0         1       0   \n",
       "4           -1        0        0                        0         0       0   \n",
       "\n",
       "         law_enforcement  mentee  uncle_aunt  competitor  ...  client  enemy   \n",
       "inst_id                                                   ...                  \n",
       "0                      1       1           1           1  ...       1      1  \\\n",
       "1                      1       1           1           0  ...       1      0   \n",
       "2                      1       0           0           0  ...       1      0   \n",
       "3                      1       1           0           0  ...       0      0   \n",
       "4                      0       0           0           0  ...       0      0   \n",
       "\n",
       "         teacher  colleague  grandparent  classmate  adopted_child  doctor   \n",
       "inst_id                                                                      \n",
       "0              1          1            1          1              1       1  \\\n",
       "1              1          1            1          0              1       1   \n",
       "2              1          1            1          0              0       1   \n",
       "3              1          1            0          0              0       1   \n",
       "4              0          0            0          0              0       0   \n",
       "\n",
       "         coworker  direct_report  \n",
       "inst_id                           \n",
       "0               1              1  \n",
       "1               1              1  \n",
       "2               1              1  \n",
       "3               1              1  \n",
       "4               0              0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Domain\n",
    "\n",
    "## Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373bd84f7c404ecb836c9f9a11dbffe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6911\n",
      "[[660 424]\n",
      " [246 839]]\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "\n",
    "# enumerate splits\n",
    "y_true, y_pred = list(), list()\n",
    "X = np.array(wiki_df.iloc[:,1:50])\n",
    "y = np.array(wiki_df.iloc[:,0])\n",
    "\n",
    "for train_ix, test_ix in tqdm(cv.split(X), total=len(wiki_df)):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # fit model\n",
    "    #model = RandomForestClassifier(random_state=42)\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=400,random_state=42)\n",
    "    #model = DummyClassifier(strategy=\"uniform\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    # evaluate model\n",
    "    yhat = clf.predict(X_test)\n",
    "    # store\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(yhat[0])\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('Accuracy: %.4f' % acc)\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3301, 1: 1651, -1: 1651})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978550bf874345bb8b6171d7fd6f97b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3302 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5781\n",
      "[[ 873  778]\n",
      " [ 615 1036]]\n"
     ]
    }
   ],
   "source": [
    "cv = LeaveOneOut()\n",
    "\n",
    "# enumerate splits\n",
    "y_true, y_pred = list(), list()\n",
    "X = np.array(se_df.iloc[:,1:50])\n",
    "y = np.array(se_df.iloc[:,0])\n",
    "\n",
    "for train_ix, test_ix in tqdm(cv.split(X), total=len(se_df)):\n",
    "    # split data\n",
    "    X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "    y_train, y_test = y[train_ix], y[test_ix]\n",
    "    # fit model\n",
    "    #model = RandomForestClassifier(random_state=42)\n",
    "    clf = LogisticRegression(solver='lbfgs', max_iter=400,random_state=42)\n",
    "    #model = DummyClassifier(strategy=\"uniform\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    # evaluate model\n",
    "    yhat = clf.predict(X_test)\n",
    "    # store\n",
    "    y_true.append(y_test[0])\n",
    "    y_pred.append(yhat[0])\n",
    "# calculate accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print('Accuracy: %.4f' % acc)\n",
    "print(confusion_matrix(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-domain\n",
    "\n",
    "## trained on wiki, test on se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_wiki = np.array(wiki_df.iloc[:,1:50])\n",
    "y_wiki = np.array(wiki_df.iloc[:,0])\n",
    "\n",
    "X_se = np.array(se_df.iloc[:,1:50])\n",
    "y_se = np.array(se_df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5763173834039976"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=400,random_state=42)\n",
    "clf.fit(X_wiki, y_wiki)\n",
    "se_pred = clf.predict(X_se)\n",
    "accuracy_score(y_se, se_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train on SE, test on Wiki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.648686030428769"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', max_iter=400,random_state=42)\n",
    "clf.fit(X_se, y_se)\n",
    "wiki_pred = clf.predict(X_wiki)\n",
    "accuracy_score(y_wiki, wiki_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
