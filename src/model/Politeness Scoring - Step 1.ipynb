{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd51471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /opt/anaconda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA SETUP: CUDA runtime path found: /usr/lib/x86_64-linux-gnu/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /opt/anaconda/lib/python3.9/site-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu/'\n",
    "\n",
    "import pandas as pd\n",
    "import datasets\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, precision_recall_fscore_support\n",
    "import wandb\n",
    "import os\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer, AutoModelForSeq2SeqLM\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PrefixTuningConfig, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm, trange\n",
    "from peft import PeftModel, PeftConfig\n",
    "from glob import glob \n",
    "from collections import defaultdict, Counter\n",
    "from os.path import basename\n",
    "\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "warnings.filterwarnings(action='ignore', category=UndefinedMetricWarning)\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # replace the 0 with other gpu ids\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "torch.cuda.set_device(1)\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14457dd1",
   "metadata": {},
   "source": [
    "# Label Politeness data with Appropriateness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "652b9711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3302\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>inst_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is `A` a global variable?  What is x?</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This is a very confusing question!  How are yo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Why not using `isnan()` from math.h? Any speci...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does your project involve some graphical user ...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Usually compilers should generate a good code ...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label  inst_id\n",
       "4               Is `A` a global variable?  What is x?      1        4\n",
       "5   This is a very confusing question!  How are yo...     -1        5\n",
       "6   Why not using `isnan()` from math.h? Any speci...     -1        6\n",
       "9   Does your project involve some graphical user ...      1        9\n",
       "11  Usually compilers should generate a good code ...      1       11"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "se_df = pd.read_csv('/shared/2/projects/contextual-appropriateness/data/sepol.csv')\n",
    "se_df['inst_id'] = range(0, 0+len(se_df))\n",
    "se_df = se_df[se_df['label'].isin([1, -1])]\n",
    "print(len(se_df))\n",
    "se_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7245d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>inst_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>Where did you learn English? How come you're t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Thanks very much for your edit to the &lt;url&gt; ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>|style=\"vertical-align: middle; padding: 3px;\"...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1</td>\n",
       "      <td>These are my numbers: 7 years in Wikipedia, 6 ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1</td>\n",
       "      <td>I couldn't tell you why glam rock was there. B...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  inst_id\n",
       "0     -1  Where did you learn English? How come you're t...        0\n",
       "1      1  Thanks very much for your edit to the <url> ar...        1\n",
       "5      1  |style=\"vertical-align: middle; padding: 3px;\"...        2\n",
       "8     -1  These are my numbers: 7 years in Wikipedia, 6 ...        3\n",
       "9     -1  I couldn't tell you why glam rock was there. B...        4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_df = pd.read_csv('/shared/2/projects/contextual-appropriateness/data/wikipol.csv')\n",
    "wiki_df.drop_duplicates(inplace=True,ignore_index=True, subset='text', keep=\"first\")\n",
    "wiki_df = wiki_df[['label','text']]\n",
    "wiki_df = wiki_df[wiki_df['label'].isin([1, -1])]\n",
    "wiki_df['inst_id'] = range(0, 0+len(wiki_df))\n",
    "print(len(wiki_df))\n",
    "wiki_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c700a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_to_verbalization = {\n",
    "    \"friend\": \"a person to their friend\",\n",
    "    \"parent\":\"a parent to their child\",\n",
    "    \"child\":\"a child to their parent\",\n",
    "    \"sibling\":\"a person to their sibling\",\n",
    "    \"best friend\":\"a person to their best friend\",\n",
    "    \"best_friend\":\"a person to their best friend\",\n",
    "    \"neighbor\":\"a person to their neighbor\",\n",
    "    \"coworker\":\"a person to their coworker\",\n",
    "    \"boss\":\"a boss to their employee\",\n",
    "    \"direct report (employee)\":\"a person to their boss\",\n",
    "    \"direct_report\":\"a person to their boss\",    \n",
    "    \"student\":\"a student to their teacher\",\n",
    "    \"teacher\":\"a teacher to their student\",\n",
    "    \"cousins\":\"a person to their cousin\",\n",
    "    \"granparent\":\"a person to their grandchild\",\n",
    "    \"grandparent\":\"a person to their grandchild\",\n",
    "    \"grandchild\":\"a person to their grandparent\",    \n",
    "    \"uncle/aunt\":\"an uncle/aunt to their niece or nephew\",\n",
    "    \"uncle_aunt\":\"an uncle or aunt to their niece or nephew\",    \n",
    "    \"neice_nephew\":\"a niece or nephew to their uncle or aunt\",        \n",
    "    \"employee_in_large_company\":\"an employee in large company to another\",\n",
    "    \"married\":\"a person to their spouse\",\n",
    "    \"dating\":\"a person to the person they are dating\",\n",
    "    \"engaged\":\"a person to their fiancee\",\n",
    "    \"friends_with_benefits\":\"a person to their friend with benefits\",\n",
    "    \"divorcee\":\"a person to their ex-spouse\",\n",
    "    \"ex-girlfriend/ex-boyfriend\":\"a person to their ex-girlfriend or ex-boyfriend\",\n",
    "    \"ex_dating\":\"a person to their ex-girlfriend or ex-boyfriend\",    \n",
    "    \"step-sibling\":\"a person to their step-sibling\",\n",
    "    \"step_sibling\":\"a person to their step-sibling\",    \n",
    "    \"fan\":\"a fan to their hero\",\n",
    "    \"hero\":\"a hero to their fan\",\n",
    "    \"enemy\":\"a person to their enemy\",\n",
    "    \"rival\":\"a person to their rival\",\n",
    "    \"competitor\":\"a person to their competitor\",\n",
    "    \"complete_stranger\":\"a person to a complete stranger\",\n",
    "    \"acquaintance\":\"a person to an acquaintance\",\n",
    "    \"person_with_authority\":\"a person with authority to a subordinate\",\n",
    "    \"law_enforcement\":\"a member of law enforcement to a community member\",\n",
    "    \"classmate\":\"a person to their classmate\",\n",
    "    \"sports_teammate\":\"a person to their sports teammate\",\n",
    "    \"club_member\":\"a person to a member of their club\",\n",
    "    \"adopted_child\":\"an adopted child to their parent\",\n",
    "    \"adopted child\":\"an adopted child to their parent\",\n",
    "    \"domestic_partner\":\"a person to their domestic partner\",\n",
    "    \"person_having_an_affair\":\"a person having an affair to their partner\",\n",
    "    \"mentor\":\"a mentor to their mentee\",\n",
    "    \"mentee\":\"a mentee to their mentor\",\n",
    "    \"landlord\":\"a landlord to their tenant\",\n",
    "    \"colleague\":\"a person to their colleague\",\n",
    "    \"childhood_friend\":\"a person to their childhood friend\",\n",
    "    \"old_friend\":\"a person to an old friend\",\n",
    "    \"client\":\"a client to their lawyer\",\n",
    "    \"lawyer\":\"a lawyer to their client\",\n",
    "    \"patient\":\"a patient to their doctor\",\n",
    "    \"doctor\":\"a doctor to their patient\",\n",
    "}\n",
    "len(relationship_to_verbalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c8d0c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = '/shared/2/projects/contextual-appropriateness/data/final-annotated-data-cleaned/'\n",
    "train_df = pd.read_csv(datadir + 'train.csv')\n",
    "rels = set(train_df.relationship)\n",
    "len(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2553d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verbalize(rel, quote):\n",
    "    if rel in relationship_to_verbalization:\n",
    "        desc = relationship_to_verbalization[rel]\n",
    "    else:\n",
    "        desc = relationship_to_verbalization[rel.replace(' ', '_')]\n",
    "    text = 'Rate whether it is inappropriate for this message to be said in the following social setting?\\nsetting: from %s\\nmessage: %s\\nanswer (yes or no):' % (desc, quote)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b730e5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11da70f1ccac42388b10e379020cd1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_rel_wiki_df = defaultdict(list)\n",
    "for row in tqdm(wiki_df.itertuples(), total=len(wiki_df)):\n",
    "    text = row.text\n",
    "    label = row.label\n",
    "    for rel in rels:\n",
    "        all_rel_wiki_df['inst_id'].append(row.inst_id)\n",
    "        all_rel_wiki_df['text'].append(verbalize(rel, text))\n",
    "        all_rel_wiki_df['relationship'].append(rel)\n",
    "        all_rel_wiki_df['label'].append(label)\n",
    "        all_rel_wiki_df['answer'].append('yes' if label < 0 else 'no')\n",
    "all_rel_wiki_df = pd.DataFrame(all_rel_wiki_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "923dad64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e734e6a5f5d2426d97d503868649a310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6603 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_rel_se_df = defaultdict(list)\n",
    "for row in tqdm(se_df.itertuples(), total=len(se_df)):\n",
    "    text = row.text\n",
    "    label = row.label\n",
    "    for rel in rels:\n",
    "        all_rel_se_df['inst_id'].append(row.inst_id)\n",
    "        all_rel_se_df['text'].append(verbalize(rel, text))\n",
    "        all_rel_se_df['relationship'].append(rel)\n",
    "        all_rel_se_df['label'].append(label)\n",
    "        all_rel_se_df['answer'].append('yes' if label < 0 else 'no')\n",
    "all_rel_se_df = pd.DataFrame(all_rel_se_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "407a60de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106281, 323547)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_rel_wiki_df), len(all_rel_se_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11732a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rel_wiki_ds = Dataset.from_pandas(all_rel_wiki_df)\n",
    "all_rel_se_ds = Dataset.from_pandas(all_rel_se_df)\n",
    "\n",
    "politeness_dd = DatasetDict()\n",
    "politeness_dd['wiki'] = all_rel_wiki_ds\n",
    "politeness_dd['se'] = all_rel_se_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "328b0e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "model_name_or_path = \"google/flan-t5-xl\"\n",
    "tokenizer_name_or_path = \"google/flan-t5-xl\"\n",
    "best_model_dir = '/shared/2/projects/contextual-appropriateness/models/peft/google/flan-t5-xl/seed-12345//best'\n",
    "\n",
    "text_column = \"text\"\n",
    "label_column = \"answer\"\n",
    "max_length = 192\n",
    "lr = 1e-2\n",
    "num_epochs = 20\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7f7f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = examples[text_column]\n",
    "    targets = examples[label_column]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=2, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = labels[\"input_ids\"]\n",
    "    labels[labels == tokenizer.pad_token_id] = -100\n",
    "    model_inputs[\"labels\"] = labels\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba8e8195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=8):   0%|          | 0/106281 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=8):   0%|          | 0/323547 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_politeness_dd = politeness_dd.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=8,\n",
    "    remove_columns=politeness_dd[\"wiki\"].column_names,\n",
    "    load_from_cache_file=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0783b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1426366fbb984475a7bda38111099fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(best_model_dir)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, best_model_dir)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print('model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "517f9ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51526f21e52a4045b73aee3c4a4c19f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/691 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wiki_dataloader = DataLoader(\n",
    "    processed_politeness_dd['wiki'], shuffle=False, collate_fn=default_data_collator, \n",
    "    batch_size=154, pin_memory=True\n",
    ")\n",
    "\n",
    "wiki_preds = []\n",
    "for step, batch in enumerate(tqdm(wiki_dataloader)):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    wiki_preds.extend(\n",
    "        tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), \n",
    "                               skip_special_tokens=True)\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "100173e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c00c1c4b1c6342ee942d7ac1bccc7051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2101 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se_dataloader = DataLoader(\n",
    "    processed_politeness_dd['se'], shuffle=False, collate_fn=default_data_collator, \n",
    "    batch_size=154, pin_memory=True\n",
    ")\n",
    "\n",
    "se_preds = []\n",
    "for step, batch in enumerate(tqdm(se_dataloader)):\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    se_preds.extend(\n",
    "        tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), \n",
    "                               skip_special_tokens=True)\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50035596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106281, 106281)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki_preds), len(all_rel_wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdb91f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes', 'yes']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a8322a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rel_wiki_df['predicted'] = wiki_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ed377b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323547, 323547)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(se_preds), len(all_rel_se_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d47a05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rel_se_df['predicted'] = se_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae031720",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_outdir = '/shared/2/projects/contextual-appropriateness/results/peft/'\n",
    "all_rel_wiki_df.to_csv(peft_outdir + 'politeness.wiki.labeled.csv', index=False)\n",
    "all_rel_se_df.to_csv(peft_outdir + 'politeness.se.labeled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
